# ğŸ”‹ Lumion Dashboard - Sistema de GestÃ£o EnergÃ©tica Residencial(CTWP)

  - [ğŸ‘€ VisÃ£o Geral](#-visÃ£o-geral)

  - [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)

  - [ğŸš€ Funcionalidades](#-funcionalidades)
        
  - [ğŸ“‹ PrÃ©-requisitos](#-prÃ©-requisitos)

  - [âš™ï¸ ConfiguraÃ§Ã£o](#ï¸-configuraÃ§Ã£o)
    

  - [ğŸš€ ExecuÃ§Ã£o](#-execuÃ§Ã£o)



## ğŸ‘€ VisÃ£o Geral
Lumion Dashboard interativo para monitoramento e gestÃ£o de energia residencial usando Streamlit e Plotly. Com o objetivo de gerenciamento, otimizaÃ§Ã£o do consumo energÃ©tico em residÃªncias, foco na reduÃ§Ã£o de custos e aumento da eficiÃªncia.


## ğŸ“ Estrutura do Projeto

* **energy-dashboard//**: DiretÃ³rio raiz do projeto.
    * **energy_dashboard.py/**: Script principal
    * **requirements.txt/**: DependÃªncias do projeto
    * **README.md:** Este arquivo
 
## ğŸš€ Funcionalidades
- Dashboard interativo com mÃ©tricas em tempo real
- GrÃ¡fico de consumo energÃ©tico
- Controles para modo de operaÃ§Ã£o (AutomÃ¡tico, Manual, Economia)
- Alertas e recomendaÃ§Ãµes para economia de energia
- GeraÃ§Ã£o de dados simulados para demonstraÃ§Ã£o

## ğŸ“‹ PrÃ©-requisitos
- Python 3.7+
- pip (gerenciador de pacotes Python)

## âš™ï¸ ConfiguraÃ§Ã£o
1. Clone o repositÃ³rio:
'''
git clone https://github.com/seu-usuario/energy-dashboard.git
'''
'''
cd energy-dashboard

2. Instale as dependÃªncias:
'''
pip install -r requirements.txt
'''
PAREI AQUI
### PrÃ©-requisitos
- Docker e Docker Compose
- Python 3.8+
- PostgreSQL 13+
- pip (Python package manager)



  - [ğŸ“Š Pipeline de Dados](#-pipeline-de-dados)
    - [Coleta (ANEEL)](#coleta-aneel)
    - [Processamento](#processamento)
    - [Armazenamento](#armazenamento)

  - [ğŸ”— IntegraÃ§Ã£o](#-integraÃ§Ã£o)
    - [Com AICSS](#com-aicss)
    - [Com SCR](#com-scr)

  - [ğŸ“ˆ MÃ©tricas e KPIs](#-mÃ©tricas-e-kpis)

  - [ğŸ”’ SeguranÃ§a](#-seguranÃ§a)

  - [ğŸ“š DocumentaÃ§Ã£o API](#-documentaÃ§Ã£o-api)

  - [ğŸ”„ ManutenÃ§Ã£o](#-manutenÃ§Ã£o)

  - [ğŸ“± Interface Web](#-interface-web)

  - [ğŸŒ Endpoints API](#-endpoints-api)
    - [Dados ANEEL](#dados-aneel)
    - [AnÃ¡lise](#anÃ¡lise)
    - [IntegraÃ§Ã£o AICSS](#integraÃ§Ã£o-aicss)

  - [ğŸ“Š VisualizaÃ§Ã£o](#-visualizaÃ§Ã£o)
    - [Dashboards](#dashboards)
    - [RelatÃ³rios](#relatÃ³rios)

  - [ğŸ”— Links Ãšteis](#-links-Ãºteis)

  - [ğŸ¤ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)

  - [ğŸ“„ LicenÃ§a](#-licenÃ§a)


     



### InstalaÃ§Ã£o
1. Clone o repositÃ³rio:

```bash
git clone <repository-url>
cd cds
```
2. Configure o ambiente:

```python -m venv venv
source venv/bin/activate  # Linux/Mac
```
```
.\venv\Scripts\activate   # Windows
```
```
pip install -r requirements.txt
```

3. Configure as variÃ¡veis de ambiente:

```cp .env.example .env
# Edite .env com suas credenciais
```

## ğŸš€ ExecuÃ§Ã£o

1. Inicie os containers:

```
docker-compose up -d
```

2. Execute o pipeline:

```
python scripts/pipeline.py
```

## ğŸ“Š Pipeline de Dados

### Coleta (ANEEL)
O processo comeÃ§a com a extraÃ§Ã£o de dados diretamente da API da ANEEL, que permite o acesso a informaÃ§Ãµes oficiais de maneira automatizada. Essa extraÃ§Ã£o ocorre diariamente para assegurar que o banco de dados esteja sempre atualizado. Os dados sÃ£o recebidos no formato JSON/CSV.
- API REST para dados oficiais
- Periodicidade: DiÃ¡ria
- Formato: JSON/CSV

### Processamento
Na etapa de processamento os dados passam pelas etapas listadas abaixo, para assegurar a qualidade e utilidade:

- Limpeza: SÃ£o eliminados dados duplicados, inconsistentes ou invÃ¡lidos, garantindo a integridade dos dados que serÃ£o armazenados.
- ValidaÃ§Ã£o: Os dados sÃ£o checados para confirmar que atendem aos padrÃµes esperados. Por exemplo, as datas devem estar em um formato correto, e os valores numÃ©ricos devem estar dentro de um intervalo aceitÃ¡vel.
- TransformaÃ§Ã£o de formatos: Os dados podem ser convertidos para um formato mais adequado para armazenamento ou anÃ¡lise. Isso pode incluir a conversÃ£o de tipos de dados, o cÃ¡lculo de novos valores ou a agregaÃ§Ã£o de informaÃ§Ãµes.
- Enriquecimento: Os dados coletados sÃ£o complementados com informaÃ§Ãµes adicionais do AICSS, proporcionando uma visÃ£o mais ampla e contextualizada, (referÃªncia em `aicss/readme.md`, linhas 447-450).


### Armazenamento
Os dados processados sÃ£o armazenados em um banco de dados PostgreSQL, escolhemos esse SGBD, pois apresenta alta performance, escalabilidade e flexibilidade. Para otimizar o armazenamento e as consultas, sÃ£o utilizadas as seguintes tÃ©cnicas:

- Particionamento: As tabelas sÃ£o divididas em partes menores (partiÃ§Ãµes), melhorando o desempenho de consultas em grandes volumes de dados.
- Ãndices: foram criados Ã­ndices em colunas para acelerar a busca por registros especÃ­ficos.
- Backup AutomÃ¡tico: O banco de dados Ã© respaldado regularmente para garantir a recuperaÃ§Ã£o dos dados em caso de falhas ou perdas acidentais.

```mermaid
flowchart LR
    subgraph Coleta de Dados
        A((API ANEEL)) --> B((Coleta DiÃ¡ria))
    end

    subgraph Processamento
        B --> C((Limpeza e ValidaÃ§Ã£o))
        C --> D((TransformaÃ§Ã£o))
        D --> E((Enriquecimento com AICSS))
    end

    subgraph Armazenamento
        E --> F((PostgreSQL))
        F --> G((Particionamento))
        F --> H((IndexaÃ§Ã£o))
        F --> I((Backup AutomÃ¡tico))
    end
```

## ğŸ”— IntegraÃ§Ã£o

Com AICSS - Sistema automatizado de controle de iluminaÃ§Ã£o residencial que otimiza o consumo de energia atravÃ©s de sensores e automaÃ§Ã£o inteligente. O sistema gerencia tanto a iluminaÃ§Ã£o interna quanto externa, considerando fatores como luminosidade ambiente e presenÃ§a de pessoas.
- Dados de sensores (referÃªncia em `aicss/src/main.cpp`, linhas 5-10)
- MÃ©tricas de consumo
- Alertas em tempo real

Com SCR - Realiza anÃ¡lise completa de dados de geraÃ§Ã£o de energia distribuÃ­da, utilizando dados da AgÃªncia Nacional de Energia ElÃ©trica - ANEEL, o cÃ³digo automatiza o download, processamento e anÃ¡lise de dados, gerando resultados estatÃ­sticos, grÃ¡ficos e relatÃ³rios completos, facilitando a compreensÃ£o da geraÃ§Ã£o de energia distribuÃ­da no Brasil.
- ExportaÃ§Ã£o para anÃ¡lise R (referÃªncia em `aicss/readme.md`, linhas 457-460)
- ImportaÃ§Ã£o de prediÃ§Ãµes
- MÃ©tricas de desempenho

## ğŸ“ˆ MÃ©tricas e KPIs
MÃ©tricas e KPIs sÃ£o indicadores essenciais que nos ajudam a medir o desempenho e a eficÃ¡cia de um sistema. No contexto de um sistema de anÃ¡lise de dados, como o Lumion Analytics, essas mÃ©tricas sÃ£o fundamentais para assegurar a qualidade dos resultados e otimizar os processos. A seguir, vamos detalhar cada uma das mÃ©tricas mencionadas:

- Tempo de processamento ETL (Extract, Transform, Load): Essa mÃ©trica Ã© importante porque um tempo de processamento reduzido assegura que o data warehouse seja atualizado rapidamente, o que permite anÃ¡lises mais Ã¡geis e decisÃµes baseadas em dados mais recentes. Para melhorar essa mÃ©trica, Ã© possÃ­vel otimizar as consultas SQL, utilizar ferramentas de ETL mais eficientes, aplicar paralelismo e realizar indexaÃ§Ã£o.

- LatÃªncia de queries: O ideial Ã© que essa mÃ©trica esteja sempre baixa, pois uma baixa latÃªncia permite que os usuÃ¡rios obtenham respostas rÃ¡pidas Ã s suas perguntas, o que facilita a tomada de decisÃµes. Para melhorar essa mÃ©trica, Ã© possÃ­vel criar Ã­ndices adequados, otimizar as consultas SQL, utilizar cache e investir em hardware mais potente.

- Taxa de sucesso de coleta: Essa mÃ©trica deve estar sempre alta, porque uma alta taxa de sucesso assegura a integridade dos dados e a confiabilidade das anÃ¡lises. Para melhorar essa mÃ©trica, Ã© necessÃ¡rio monitorar as fontes de dados, implementar mecanismos de repetiÃ§Ã£o e alertas para falhas, alÃ©m de utilizar ferramentas de monitoramento robustas.

- Qualidade dos dados: Essa mÃ©trica mede a precisÃ£o, completude, consistÃªncia e relevÃ¢ncia dos dados, ela Ã© importante porque dados de alta qualidade sÃ£o essenciais para gerar insights confiÃ¡veis e tomar decisÃµes assertivas. Para melhorar essa mÃ©trica, Ã© fundamental implementar processos de limpeza e validaÃ§Ã£o de dados, realizar anÃ¡lises exploratÃ³rias de dados e utilizar ferramentas de profiling de dados.

## ğŸ”’ SeguranÃ§a
- AutenticaÃ§Ã£o JWT: A assinatura digital assegura a integridade do token e previne qualquer manipulaÃ§Ã£o. O servidor nÃ£o precisa manter informaÃ§Ãµes de sessÃ£o, o que torna o sistema mais escalÃ¡vel e seguro. E pode ser utilizado em uma variedade de aplicaÃ§Ãµes e plataformas.

- SSL/TLS (Secure Sockets Layer/Transport Layer Security): BenefÃ­cios confidencialidade, integridade e autenticidade

- Backup AutomÃ¡tico: BenefÃ­cios recuperaÃ§Ã£o de dados, conformidade e tranquilidade

- Logs de auditoria: BenefÃ­cios investigaÃ§Ã£o de incidentes, anÃ¡lise de comportamento e conformidade

## ğŸ“š DocumentaÃ§Ã£o API
DisponÃ­vel em: `/docs/api.md`

## ğŸ”„ ManutenÃ§Ã£o
- Backup diÃ¡rio automatizado
- Monitoramento 24/7
- Alertas em tempo real
- Logs detalhados

## ğŸ“± Interface Web
- Dashboard em tempo real
- GrÃ¡ficos interativos
- RelatÃ³rios customizados
- Controle de acesso

## ğŸŒ Endpoints API

### Dados ANEEL

``` http
GET /api/v1/aneel/consumo
GET /api/v1/aneel/tarifas
POST /api/v1/aneel/sync
```

### AnÃ¡lise

``` http
GET /api/v1/analytics/consumo
GET /api/v1/analytics/previsao
GET /api/v1/analytics/relatorios
```
### IntegraÃ§Ã£o AICSS

``` http
POST /api/v1/aicss/dados
GET /api/v1/aicss/status
PUT /api/v1/aicss/config
```

## ğŸ“Š VisualizaÃ§Ã£o

### Dashboards
- Consumo em tempo real
- HistÃ³rico por perÃ­odo
- PrevisÃµes futuras
- Alertas e notificaÃ§Ãµes

### RelatÃ³rios
- DiÃ¡rios
- Semanais
- Mensais
- Personalizados

## ğŸ”— Links Ãšteis
- [DocumentaÃ§Ã£o API](/docs/api.md)
- [Guia de ContribuiÃ§Ã£o](/CONTRIBUTING.md)
- [Changelog](/CHANGELOG.md)

## ğŸ¤ ContribuiÃ§Ã£o
1. Fork o projeto
2. Crie sua branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a
DistribuÃ­do sob a licenÃ§a MIT. Veja `LICENSE` para mais informaÃ§Ãµes.
